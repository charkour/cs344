Charles Kornoelje | Lab09 | CS 344 | 4/12/20 | Cal Uni

a. Try Chollet’s “Further experiments”. Do any of the alternatives do better than the suggested architecture? Why or why not?
One hidden layer does better than two hidden layers on test accuracy (88.78% 1 layer, 88.36% 2 layers).
Other than that barley having a better accuracy, nothing else beat the default architecture. This is probably
because Chollet has good intuition for networks because he wrote the textbook so he knows what combinations
generally work best. When the test accuracy was lower, the validation accuracy was generally lower than the
validation accuracy in the normal architecture but not always. It makes sense that the validation accuracy varies
some, because it is data the model hasn't seen before, so it could happen to fit slightly better when model
modifications are made, but nothing substantial. Tanh activation had the highest accuracy on the training data,
probably because it isn't as flexible as RELU, so it trains super well on the training data but it is not
general enough for outside data. It makes sense that more hidden layers and more layers does worse than the default
because they are likely overfitting. 8 units does almost as well as 16 units, which makes me think 16 might be too high.
MSE doesn't work as well as binary_crossentropy because MSE doesn't work as well for outputs that are probabilities
and binary_crossentroy does work with them.


Did it with four epochs
Normal architecture:
loss: 0.1800 - binary_accuracy: 0.9413 - val_loss: 0.2813 - val_binary_accuracy: 0.8891
test acc: [0.2914810848617554, 0.8836399912834167]

We were using 2 hidden layers. Try to use 1 or 3 hidden layers and see how it affects validation and test accuracy.
3 hidden layers
loss: 0.1728 - binary_accuracy: 0.9477 - val_loss: 0.2862 - val_binary_accuracy: 0.8849 - ETA: 1s - loss: 0.1741 - binary_accuracy: 0.9517
test acc: [0.31374298330307004, 0.8784800171852112]

1 hidden layer
loss: 0.2168 - binary_accuracy: 0.9349 - val_loss: 0.2813 - val_binary_accuracy: 0.8907
test acc: [0.2804577333831787, 0.8878399729728699]

Try to use layers with more hidden units or less hidden units:
8 units
loss: 0.2269 - binary_accuracy: 0.9353 - val_loss: 0.2857 - val_binary_accuracy: 0.8905
test acc: [0.2967992540645599, 0.8815600275993347]

32 units
loss: 0.1568 - binary_accuracy: 0.9449 - val_loss: 0.2820 - val_binary_accuracy: 0.8896
test acc: [0.316996708574295, 0.8792799711227417]

Try to use the mse loss function instead of binary_crossentropy.
loss: 0.0490 - binary_accuracy: 0.9471 - val_loss: 0.0824 - val_binary_accuracy: 0.8896
test acc: [0.08597981074213981, 0.8830000162124634]

Try to use the tanh activation (an activation that was popular in the early days of neural networks) instead of relu.
loss: 0.1510 - binary_accuracy: 0.9501 - val_loss: 0.2751 - val_binary_accuracy: 0.8870
test acc: [0.3320160329771042, 0.8744800090789795]
