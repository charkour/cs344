{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 2\n",
    "## Charles Kornoelje\n",
    "### CS 344"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Spam filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'i': 0.5, 'am': 0.99, 'spam': 0.99, 'do': 0.3333333333333333, 'not': 0, 'like': 0.3333333333333333, 'that': 0, 'spamiam': 0, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Filter based on Paul Graham’s A Plan for Spam, and Prof. VL's email.\n",
    "\n",
    "# Minimum occurrence threshold count\n",
    "THRESHOLD = 1\n",
    "\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "def count_occurrences(corpus, count):\n",
    "    \"\"\" Counts the number of word occurrences in the corpora.\n",
    "    Referenced: https://www.geeksforgeeks.org/python-combine-two-dictionary-adding-values-for-common-keys/\n",
    "    https://stackoverflow.com/questions/764235/dictionary-to-lowercase-in-python\n",
    "    \"\"\"\n",
    "    for email in corpus:\n",
    "        count += Counter(email)\n",
    "    return dict((k.lower(), v) for k, v in count.items())\n",
    "    \n",
    "def probability_email_containing_word_is_spam(word):\n",
    "    \"\"\"\n",
    "    Adapted from the article\n",
    "    Finds the probability an email is spam if it contains the word\n",
    "    Closer to 1, means more probable to be spam.\n",
    "    \"\"\"\n",
    "    g = 2*good[word] if word in good else 0\n",
    "    b = bad[word] if word in bad else 0\n",
    "    if g + b > THRESHOLD:  # changed to one\n",
    "        return max(0.01, min(0.99, min(1.0, b / nbad) / (min(1.0, g / ngood) + min(1.0, b / nbad))))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_spam_prob(email):\n",
    "    \"\"\"\n",
    "    Will calculate the probability that an email is spam.\n",
    "    The closer to one, the more probable it is the email is spam.\n",
    "    \"\"\"\n",
    "    prod = 1\n",
    "    complement = 1\n",
    "    for element in email:\n",
    "        prod *= probs[element.lower()]\n",
    "        complement *= (1 - probs[element.lower()])\n",
    "    return prod / (prod + complement)\n",
    "\n",
    "# get word counts\n",
    "bad = count_occurrences(spam_corpus, Counter())\n",
    "good = count_occurrences(ham_corpus, Counter())\n",
    "nbad = len(spam_corpus)\n",
    "ngood = len(ham_corpus)\n",
    "\n",
    "g_keys = list(good.keys())\n",
    "b_keys = list(bad.keys())\n",
    "\n",
    "# combine keys\n",
    "# https://stackoverflow.com/questions/1319338/combining-two-lists-and-removing-duplicates-without-removing-duplicates-in-orig\n",
    "combined_keys = b_keys\n",
    "combined_keys.extend(k for k in g_keys if k not in combined_keys)\n",
    "\n",
    "# create a third hash of probabilities\n",
    "probs = dict()\n",
    "for key in combined_keys:\n",
    "    probs[key] = probability_email_containing_word_is_spam(key)\n",
    "\n",
    "print(probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary contains the words of the corpora followed by their probabilities that the email\n",
    "is spam if it contains that word. The closer to 1, the more probable the email\n",
    "is spam.\n",
    "\n",
    "Because the threshold is set to 1, words that only occur one like \"not\" have\n",
    "a probability of zero because there is not enough information about the\n",
    "word to know if it will show up more in spam than ham.\n",
    "\n",
    "(Note: I wasn't sure if the threshold could be `b + g >= 1`, if that is the case\n",
    "then the output changes slightly. But I think using `b + g > 1` makes more\n",
    "sense to show we can't decide on probabilities if the word occurrence is low:\n",
    "`{'i': 0.5, 'am': 0.99, 'spam': 0.99, 'do': 0.3333333333333333, 'not': 0.99, 'like': 0.3333333333333333, 'that': 0.99, 'spamiam': 0.99, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01}\n",
    "`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2.6025508824397714e-09\n",
      "0.3333333333333333\n",
      "0.9999999895897965\n",
      "0.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(calculate_spam_prob(ham_corpus[0]))\n",
    "print(calculate_spam_prob(ham_corpus[1]))\n",
    "print(calculate_spam_prob(spam_corpus[0]))\n",
    "print(calculate_spam_prob(spam_corpus[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that the first two emails (ham emails) have very\n",
    "low probabilities of being spam. And of the second two emails, the first one\n",
    "has a high probability of being labeled spam, but the last email\n",
    "is likely not spam because of the there is not enough\n",
    "information about the words it contains to provide a label, so it \n",
    "considers it not spam.\n",
    "\n",
    "This is Bayesian because it uses a bayesian combination of probabilities to \n",
    "decide if an email is spam or not, rather than a score. This spam filter\n",
    "is Bayesian in its approach because it is able to describe the probability\n",
    "of an event based on prior knowledge. The prior knowledge is the probability\n",
    "of an email being spam if it contains a particular word. Using the combined\n",
    "probabilities of emails containing words being spam, this filter can label \n",
    "incoming mail as spam or not thanks to the training from prior emails labeled \n",
    "spam and not spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Bayesian Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "False: 0.5, True: 0.5\n",
      "False: 0.9, True: 0.1\n",
      "False: 0.952, True: 0.0476\n",
      "False: 0.01, True: 0.99\n",
      "False: 0.639, True: 0.361\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "'''\n",
    "This implements the Bayesian network shown in the text, Figure 14.12a\n",
    "adapted from Prof. VL's network.py.\n",
    "'''\n",
    "\n",
    "from probability import BayesNet, enumeration_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "# From AIMA code (probability.py) - Fig. 14.12a - rain/wet grass example\n",
    "cloudy = BayesNet([\n",
    "    ('Cloudy', '', 0.50),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.10, F: 0.50}),\n",
    "    ('Rain', 'Cloudy', {T: 0.80, F: 0.20}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.90, (F, T): 0.90, (F, F): 0.00}),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.b)\n",
    "The number of independent values in the full joint probability distribution\n",
    "is 2^4 = 16. There are four variables, each with a T/F value.\n",
    "\n",
    "### 2.c)\n",
    "The number of independent values in the Bayesian network for this domain\n",
    "is 9. This is due to the structure of the Bayesian network. We are able to make \n",
    "simplifications due to the assumptions based on how the network is structured.\n",
    "\n",
    "Because Bayesian networks represent variables and their conditional probabilities,\n",
    "less values are needed to be calculated than a full join probability distribution.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "i. False: 0.5, True: 0.5\n",
      "ii. False: 0.9, True: 0.1\n",
      "iii. False: 0.952, True: 0.0476\n",
      "iv. False: 0.01, True: 0.99\n",
      "v. False: 0.639, True: 0.361\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# *P*(Cloudy)\n",
    "\"\"\"\n",
    "*P*(C) = <0.5, 0.5> (Note: <True, False>) (Given)\n",
    "\"\"\"\n",
    "print(\"i.\", enumeration_ask('Cloudy', dict(), cloudy).show_approx())\n",
    "\n",
    "# *P*(Sprinkler | cloudy)\n",
    "\"\"\"\n",
    "*P*(Sprinkler | cloudy) = <0.1, 0.9> (Given)\n",
    "\"\"\"\n",
    "print(\"ii.\", enumeration_ask('Sprinkler', dict(Cloudy=T), cloudy).show_approx())\n",
    "\n",
    "# *P*(Cloudy| the sprinkler is running and it’s not raining)\n",
    "\"\"\"\n",
    "*P*(C | s^~r)\n",
    "    = a*P*(C, s, ~r)\n",
    "    = a<P(s^~r | c)P(c), P(s^~r | ~c)P(~c)>\n",
    "    = a<P(s | c)P(~r | c)P(c), P(s | ~c)P(~r | ~c)P(~c)>\n",
    "    = a<(.1)(.2)(.5), (.5)(.8)(.5)>\n",
    "    = a<0.01, 0.2>\n",
    "    = 4.76<0.01, 0.2>\n",
    "    = <.952, .048>\n",
    "\"\"\"\n",
    "print(\"iii.\", enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), cloudy).show_approx())\n",
    "\n",
    "# *P*(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\n",
    "\"\"\"\n",
    "*P*(W | c^s^r)\n",
    "    = a*P*(W, c, s, r)\n",
    "    = a<P(w, c, s, r), P(~w, c, s, r)>\n",
    "    = a<P(w^c^s^r), P(~w^c^s^r)>\n",
    "    = a<(.99)(.5)(.1)(.8), (.01)(.5)(.1)(.8)>\n",
    "    = a<0.0396, 0.0004>\n",
    "    = 25<0.0396, 0.0004>\n",
    "    = <0.99, 0.01>\n",
    "\"\"\"\n",
    "print(\"iv.\", enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), cloudy).show_approx())\n",
    "\n",
    "# *P*(Cloudy | the grass is not wet)\n",
    "\"\"\"\n",
    "*P*(C | ~w)\n",
    "    = *P*(~w | C)*P*(C)\n",
    "    = aΣ(s, r)*P*(C, s, r, ~w)\n",
    "    = skipped the writing out of P(events), very long.\n",
    "    = a<(.5)[(.1)(.8)(.01)+(.1)(.2)(.1)+(.9)(.8)(.1)+(.9)(.2)(1)], (.5)[(.5)(.2)(.01)+(.5)(.8)(.1)+(.5)(.2)(.1)+(.5)(.8)(1)]>\n",
    "    = a<0.1274, 0.2255>\n",
    "    = 2.83<0.1274, 0.2255>\n",
    "    = <.361, .639> \n",
    "\"\"\"\n",
    "print(\"v.\", enumeration_ask('Cloudy', dict(WetGrass=F), cloudy).show_approx())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}