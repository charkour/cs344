{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 4\n",
    "Charles Kornoelje | CS 344 | 4/23/2020 | Cal Uni\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1\n",
    "\t    I believe that \"deep\" neural networks are a breakthrough and will be widely used in the future. The reason for\n",
    "\tthis is because neural networks have their foundation in ideas that have been around since the 1950s, such as\n",
    "\tperceptrons and connectionism which would come in the 80s. Though these old ideas have been around for many years,\n",
    "\tapplications of the ideas haven't been widely used until the 2010s with the rise of machine learning. It took until\n",
    "\tthe 2010s to have fast enough processors and large amounts of data to use create useful neural networks. The\n",
    "\tapplications of neural networks are vast so the use of these networks will continue to be used for years. Such\n",
    "\tapplications are for identifying zip codes on envelopes (as studied in class with the MNIST dataset) as well as\n",
    "\tpersonalized ads, suggestion features (such as recommended videos on YouTube or Netflix, friend suggestions on\n",
    "\tFaceBook, project suggestions on Amazon), and deciding on sentencing for those guilty of crimes. We generate so\n",
    "\tmuch big data, that we need neural networks as a way to find meaningful answers. And although we use neural\n",
    "\tnetworks, there is still a need to improve them and learn how to apply their usefulness in a better way.\n",
    "\tInterestingly, the applications of neural networks are too good that Amazon is removing suggestions of products\n",
    "\tto limit the amount they are selling during the COVID-19 pandemic\n",
    "\t([a Robinhood Article](https://snacks.robinhood.com/newsletters/25IZbjYcBGpV6UMaUGQIGz/)\n",
    "\t[and a forum post](https://www.resetera.com/threads/did-amazon-remove-their-%E2%80%9Ccustomers-who-bought-viewed-this-item-also-bought-viewed-%E2%80%9D-section.177169/)).\n",
    "\tBecause of the wide application of \"deep\" neural networks, large amounts of data generated, technological\n",
    "\tadvancements, and companies as well as the individual pushing for efficient problem solving, these neural\n",
    "\tnetworks are here to stay for a long time.\n",
    "\t\n",
    "\t\tMore efficiencies and techniques for neural networks will happen in the future, making the \"deep\" neural networks\n",
    "\teven more powerful, thus solidifying their place in society. Humans desperately want to create some sort of\n",
    "\tartificial intelligence that mimics the human mind, and using networks the relate to neurons in the mind I believe\n",
    "\tis a critical step into creating human-like AI. We are advancing quicker than ever, and if we have been using\n",
    "\tneural networks since the 2010s instead of moving onto something new, there is a reason to suspect that this\n",
    "\ttechnology isn't a bust. Although I do contend that current neural networks are mostly used a pattern matching\n",
    "\tand perception and lack things like logical deduction. I believe that neural networks might be used as part of\n",
    "\tlarger AI systems in the future. Currently, neural networks rely on good data, so if we get better at getting\n",
    "\tproper data, then the results of the network will also improve. Also in the future, I see neural network use\n",
    "\tbecoming more commercialized and available to small businesses and people without a computer science background.\n",
    "\tCurrently, big tech companies are paving the path forward for neural networks, but I think additional APIs and\n",
    "\tservices will be built upon our current tools to allow wide-spread, commercial access to all. William Vorhies of\n",
    "\tData Science Central says we have reached a plateau and says that \"Automation or even well-accepted rules of thumb\n",
    "\tare still out of reach\" [from his article \"What Comes After Deep Learning\"](https://www.datasciencecentral.com/profiles/blogs/what-comes-after-deep-learning).\n",
    "\tI currently agree with this statement which is why using neural nets is an art. But with enough time, I think that\n",
    "\trules of thumb can be developed and automation of network training can be done, thus advancing neural\n",
    "\tnetworks forward."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 2\n",
    "\n",
    "![image](./bp1.JPG)\n",
    "![image](./bp2.JPG)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "model.evaluate(test_images, test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}